#! /usr/bin/env python3
"""
Senior Data Scientist.: Dr. Eddy Giusepe Chirinos Isidro

Script chatbot_ui.py
====================
Neste script, criamos a interface do usu√°rio para a aplica√ß√£o
de entrevista de simula√ß√£o com IA.

Run
---
streamlit run chatbot_ui.py --server.address localhost --server.port 8501

Executamos esse comando porque √© mais seguro, j√° que o streamlit n√£o permite
acesso ao microfone se n√£o estiver em localhost.

NOTA
====
O App est√° funcional, mas falta alguns pequenos ajustes para melhorar
a experi√™ncia do usu√°rio.
"""
import asyncio
import os
import tempfile

import streamlit as st
import whisper  # https://pypi.org/project/openai-whisper/
from streamlit_mic_recorder import mic_recorder

from interview_practice_system import (
    evaluate_answer,
    generate_follow_up_question,
    initialize_preparation_crew,
)

st.title("ü§ó Entrevista Simulada com IA ü§ó")

# Inicializa o estado da sess√£o:
if "messages" not in st.session_state:
    st.session_state.messages = []
    st.session_state.interview_started = False
    st.session_state.current_question = None
    st.session_state.current_answer = None
    st.session_state.evaluation = None
    st.session_state.preparation_crew = None
    st.session_state.follow_up_question = None
    st.session_state.is_generating_follow_up = False

# Sidebar para configura√ß√£o da entrevista:
with st.sidebar:
    st.header("Configura√ß√£o da Entrevista")
    company_name = st.text_input("Nome da Empresa desejada", "Google")
    role = st.text_input("Cargo desejado", "Cientista de Dados Junior")
    difficulty = st.selectbox("N√≠vel de Dificuldade", ["F√°cil", "M√©dio", "Dif√≠cil"], index=1)

    st.divider()
    st.subheader("üé§ Configura√ß√µes de √Åudio")

    whisper_model = st.selectbox(
        "Modelo Whisper utilizado para reconhecimento de voz",
        ["tiny", "base", "small", "medium", "large"],
        index=1,  # "base" como padr√£o
        help="""
        - tiny: Mais r√°pido, menos preciso (~1GB de RAM)
        - base: Equilibrado (recomendado) (~1GB de RAM)
        - small: Mais preciso (~2GB de RAM)
        - medium: Muito preciso (~5GB de RAM)
        - large: M√°xima precis√£o (~10GB de RAM)
        """,
    )

    st.info(
        f"""
        üé§ **Modelo atual:** `{whisper_model}`\n
        ‚úÖ **Idioma:** pt-BR\n
        üí∞ **Custo:** GR√ÅTIS (roda localmente)\n
        üîë **API Key:** N√£o necess√°ria (Open Source)\n
        """
    )

    if st.button("Iniciar Entrevista Simulada"):
        st.session_state.interview_started = True
        st.session_state.messages = []
        st.session_state.current_question = None
        st.session_state.current_answer = None
        st.session_state.evaluation = None
        st.session_state.follow_up_question = None
        st.session_state.is_generating_follow_up = False

        # Inicializa a equipe de prepara√ß√£o:
        st.session_state.preparation_crew = initialize_preparation_crew(company_name, role, difficulty)
        st.rerun()

# Exibe as mensagens do chat:
for msg in st.session_state.messages:
    with st.chat_message(msg["role"]):
        st.markdown(msg["content"])

# Inicia a entrevista se n√£o foi iniciada:
if not st.session_state.interview_started:
    st.info(
        """üëã Bem-vindo! Por favor, configure sua entrevista simulada na barra lateral e clique
        em 'Iniciar Entrevista Simulada' para come√ßar."""
    )
# Se n√£o temos uma pergunta atual, inicia a entrevista:
elif st.session_state.current_question is None:
    with st.spinner("ü§ñ Preparando sua pergunta de entrevista..."):
        # Executa a crew de prepara√ß√£o para obter a pergunta e a resposta correta:
        preparation_result = st.session_state.preparation_crew.kickoff()

        # Armazena a pergunta e a resposta correta:
        st.session_state.current_question = preparation_result.pydantic.question
        st.session_state.correct_answer = preparation_result.pydantic.correct_answer

        # Adiciona a pergunta ao chat:
        st.session_state.messages.append({"role": "assistant", "content": st.session_state.current_question})
        st.rerun()

# Obt√©m a entrada do usu√°rio:
st.write("Escolha seu m√©todo de entrada:")
input_method = st.radio("M√©todo de Entrada", ["Texto", "Voz"], horizontal=True, label_visibility="collapsed")

user_input = None  # Inicializa o user_input


def convert_speech_to_text(audio_bytes, model_name="base"):
    """
    Converte √°udio em texto usando Whisper.

    Args:
        audio_bytes: Bytes do √°udio gravado
        model_name: Nome do modelo Whisper (tiny, base, small, medium, large)

    Returns:
        str: Texto transcrito ou None se houver erro
    """
    try:
        # Cria um arquivo tempor√°rio para armazenar o √°udio:
        with tempfile.NamedTemporaryFile(delete=False, suffix=".wav") as temp_audio:
            temp_audio.write(audio_bytes)
            temp_audio_path = temp_audio.name

        try:
            # Carrega o modelo Whisper (isso ir√° baixar o modelo na primeira execu√ß√£o)
            # Na primeira vez que usar um modelo, ele ser√° baixado (~100MB-3GB)
            model = whisper.load_model(model_name)

            # Transcreve o √°udio especificando portugu√™s brasileiro
            # language='pt' for√ßa o reconhecimento em portugu√™s
            # fp16=False √© necess√°rio para CPU (a maioria dos computadores)
            result = model.transcribe(
                temp_audio_path,
                language="pt",  # Portugu√™s (Brasil/Portugal)
                fp16=False,  # Desabilita FP16 (necess√°rio para CPU)
                verbose=False,  # N√£o mostra progresso detalhado
            )
            return result["text"]
        finally:
            # Limpa o arquivo tempor√°rio
            os.unlink(temp_audio_path)

    except FileNotFoundError as e:
        if "ffmpeg" in str(e):
            st.error(
                """
                ‚ùå **Erro: FFmpeg n√£o encontrado!**
                O Whisper precisa do FFmpeg para processar √°udio.
                **Solu√ß√£o:** Execute no terminal:
                ```bash
                sudo apt update && sudo apt install -y ffmpeg
                ```
                Depois reinicie a aplica√ß√£o Streamlit.
                """
            )
        else:
            st.error(f"Arquivo n√£o encontrado: {e!s}")
        return None
    except Exception as e:
        st.error(f"Ocorreu um erro ao processar o √°udio: {e!s}")
        return None


if input_method == "Texto":
    user_input = st.chat_input("Digite sua resposta...")
else:
    # Instru√ß√µes para o usu√°rio sobre permiss√µes do microfone
    st.info(
        """
        üé§ **Importante:** Para usar o microfone:
        1. Clique em "Iniciar grava√ß√£o" abaixo
        2. Permita o acesso ao microfone quando o navegador solicitar
        3. Fale sua resposta claramente
        4. Clique em "Parar grava√ß√£o" quando terminar

        ‚ö†Ô∏è **Nota:** Se estiver usando WSL/Linux, certifique-se de que:
        - O navegador tem permiss√£o para acessar o microfone
        - A aplica√ß√£o est√° rodando em HTTPS ou localhost
        """
    )

    st.write("Clique no microfone para gravar sua resposta:")

    # Adiciona uma chave √∫nica para evitar problemas de re-renderiza√ß√£o
    audio = mic_recorder(
        start_prompt="‚ñ∂Ô∏é ‚Ä¢·Åä·Åä||·Åä|·Åã||| Iniciar grava√ß√£o",
        stop_prompt="‚èπÔ∏è Parar grava√ß√£o",
        just_once=True,
        use_container_width=True,
        key="voice_recorder",
    )

    if audio:
        # Debug: mostra que o √°udio foi capturado
        st.write(f"üìä √Åudio capturado: {len(audio['bytes'])} bytes")

        with st.spinner(f"üîÑ Convertendo √°udio para texto usando modelo '{whisper_model}'..."):
            # Converte os bytes do √°udio para texto usando o modelo selecionado
            user_input = convert_speech_to_text(audio["bytes"], model_name=whisper_model)
            if user_input:
                st.success(f"‚úÖ Reconhecido: {user_input}")
            else:
                st.error("‚ùå N√£o foi poss√≠vel reconhecer a fala. Por favor, tente novamente.")
    # Debug: indica quando o bot√£o de grava√ß√£o foi clicado mas n√£o h√° √°udio
    elif st.session_state.get("show_audio_warning", False):
        st.warning("‚è≥ Aguardando grava√ß√£o... Clique em 'Iniciar grava√ß√£o' e fale no microfone.")

if user_input is not None:
    # Adiciona a resposta do usu√°rio √†s mensagens:
    st.session_state.messages.append({"role": "user", "content": user_input})

    # Armazena a resposta do usu√°rio:
    st.session_state.current_answer = user_input

    # Mostra a mensagem de pensamento:
    with st.spinner("ü§ñ Avaliando sua resposta..."):
        # Avalia a resposta do usu√°rio:
        evaluation = evaluate_answer(
            question=st.session_state.current_question,
            user_answer=user_input,
            correct_answer=st.session_state.correct_answer,
        )

        # Adiciona a avalia√ß√£o √†s mensagens:
        st.session_state.messages.append({"role": "assistant", "content": evaluation})

        # Gera uma pergunta de follow-up se n√£o estiver gerando uma pergunta de follow-up:
        if not st.session_state.is_generating_follow_up:
            st.session_state.is_generating_follow_up = True
            try:
                # Gera uma pergunta de follow-up:
                follow_up_result = asyncio.run(
                    generate_follow_up_question(
                        question=st.session_state.current_question,
                        company_name=company_name,
                        role=role,
                        difficulty=difficulty.lower(),
                    )
                )

                # Armazena a pergunta de follow-up:
                st.session_state.follow_up_question = follow_up_result

                # Adiciona a pergunta de follow-up √†s mensagens:
                st.session_state.messages.append({"role": "assistant", "content": follow_up_result.question})

                # Configura para a pergunta de follow-up:
                st.session_state.current_question = follow_up_result.question
                st.session_state.correct_answer = follow_up_result.correct_answer
            except Exception as e:
                st.error(f"Ocorreu um erro ao gerar a pergunta de follow-up: {e!s}")
                st.session_state.current_question = None
                st.session_state.current_answer = None
        else:
            # Reinicia para a pr√≥xima pergunta:
            st.session_state.current_question = None
            st.session_state.current_answer = None

        st.session_state.is_generating_follow_up = False
        st.rerun()


# Auto-scroll:
scroll_placeholder = st.empty()
